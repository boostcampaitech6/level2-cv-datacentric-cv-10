{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 ufo json파일 -> coco  (x) tag추가 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '../data/medical/ufo/divided_train.json'\n",
    "# input_path = '../../data/medical/ufo/train.json'\n",
    "output_path = '../data/medical/ufo/train_coco.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "    'date_created': now\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{\n",
    "    'id': 1,\n",
    "    'name': 'word'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ufo_to_coco(file: Dict, output_path: str) -> None:\n",
    "    img_id = 1 #COCO는 1부터 시작\n",
    "    annotation_id = 1 #COCO는 1부터 시작\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for fname, data in file.items():\n",
    "        image = {\n",
    "            \"id\": img_id,\n",
    "            \"width\": data['img_w'],\n",
    "            \"height\": data['img_h'],\n",
    "            \"file_name\": fname,\n",
    "            \"license\": 1,\n",
    "            \"flickr_url\": None,\n",
    "            \"coco_url\": None,\n",
    "            \"date_captured\": now\n",
    "        }\n",
    "        images.append(image)\n",
    "        for anno_id, annotation in data['words'].items():\n",
    "            if annotation['illegibility'] == True:\n",
    "                continue\n",
    "            min_x = min(item[0] for item in annotation['points'])\n",
    "            min_y = min(item[1] for item in annotation['points'])\n",
    "            max_x = max(item[0] for item in annotation['points'])\n",
    "            max_y = max(item[1] for item in annotation['points'])\n",
    "            width = max_x - min_x\n",
    "            height = max_y - min_y\n",
    "            tags = annotation['tags']\n",
    "\n",
    "            coco_annotation = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": 1,\n",
    "                \"segmentation\": [[value for sublist in annotation['points'] for value in sublist]],\n",
    "                \"area\": width * height,\n",
    "                \"bbox\": [min_x, min_y, width, height],\n",
    "                \"iscrowd\": 0,\n",
    "                'tags' : tags\n",
    "            }\n",
    "            annotations.append(coco_annotation)\n",
    "            annotation_id += 1\n",
    "        img_id += 1\n",
    "    coco = {\n",
    "        'info' : info,\n",
    "        'images' : images,\n",
    "        'annotations' : annotations,\n",
    "        'licenses' : licenses,\n",
    "        'categories' : categories\n",
    "    }\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "ufo_to_coco(file['images'], output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 파일 coco -> ufo (x) 기본 tag 추가 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '../data/medical/ufo/train_coco.json'\n",
    "output_path = '../data/medical/ufo/train_coco_2_ufo.json'\n",
    "\n",
    "ufo = {\n",
    "    'images': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_bbox_to_ufo(bbox):\n",
    "    min_x, min_y, width, height = bbox\n",
    "    return [\n",
    "        [min_x, min_y],\n",
    "        [min_x + width, min_y],\n",
    "        [min_x + width, min_y + height],\n",
    "        [min_x, min_y + height]\n",
    "    ]\n",
    "\n",
    "def coco_to_ufo(file: Dict, output_path: str) -> None:\n",
    "    anno_id = 1\n",
    "    for annotation in file['annotations']:\n",
    "        file_info = file['images'][int(annotation['image_id'])-1]\n",
    "        image_name = file_info['file_name']\n",
    "        if image_name not in ufo['images']:\n",
    "            anno_id = 1\n",
    "            ufo['images'][image_name] = {\n",
    "                \"paragraphs\": {},\n",
    "                \"words\": {},\n",
    "                \"chars\": {},\n",
    "                \"img_w\": file_info[\"width\"],\n",
    "                \"img_h\": file_info[\"height\"],\n",
    "                \"tags\": [\"autoannotated\"],\n",
    "                \"relations\": {},\n",
    "                \"annotation_log\": {\n",
    "                    \"worker\": \"\",\n",
    "                    \"timestamp\": now,\n",
    "                    \"tool_version\": \"LabelMe or CVAT\",\n",
    "                    \"source\": None\n",
    "                    },\n",
    "                \"license_tag\": {\n",
    "                    \"usability\": True,\n",
    "                    \"public\": False,\n",
    "                    \"commercial\": True,\n",
    "                    \"type\": None,\n",
    "                    \"holder\": \"Upstage\"\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "            # anno_id = 1\n",
    "        ufo['images'][image_name]['words'][str(anno_id).zfill(4)] = {\n",
    "            \"transcription\": \"\",\n",
    "            \"points\":  coco_bbox_to_ufo(annotation[\"bbox\"]),\n",
    "            \"orientation\": \"Horizontal\",\n",
    "            \"language\": None,\n",
    "            \"tags\": annotation['tags'],  ## 이거 변경\n",
    "            \"confidence\": None,\n",
    "            \"illegibility\": False\n",
    "        }\n",
    "        anno_id += 1\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(ufo, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "coco_to_ufo(file, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 ufo json파일 -> coco  (o) tag 제외 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '../data/medical/ufo/divided_train.json'\n",
    "# input_path = '../../data/medical/ufo/train.json'\n",
    "output_path = '../data/medical/ufo/train_coco.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "    'date_created': now\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{\n",
    "    'id': 1,\n",
    "    'name': 'word'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_skip(annotation_tags, tags_to_skip):\n",
    "    for tag in annotation_tags:\n",
    "        if tag in tags_to_skip:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def ufo_to_coco(file: Dict, output_path: str) -> None:\n",
    "    img_id = 1 #COCO는 1부터 시작\n",
    "    annotation_id = 1 #COCO는 1부터 시작\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for fname, data in file.items():\n",
    "        image = {\n",
    "            \"id\": img_id,\n",
    "            \"width\": data['img_w'],\n",
    "            \"height\": data['img_h'],\n",
    "            \"file_name\": fname,\n",
    "            \"license\": 1,\n",
    "            \"flickr_url\": None,\n",
    "            \"coco_url\": None,\n",
    "            \"date_captured\": now\n",
    "        }\n",
    "        images.append(image)\n",
    "        for anno_id, annotation in data['words'].items():\n",
    "            if annotation['illegibility'] == True:\n",
    "                continue\n",
    "            elif should_skip(annotation['tags'], ['masked', 'excluded-region', 'maintable', 'stamp']) :#ignore_list\n",
    "                continue\n",
    "            min_x = min(item[0] for item in annotation['points'])\n",
    "            min_y = min(item[1] for item in annotation['points'])\n",
    "            max_x = max(item[0] for item in annotation['points'])\n",
    "            max_y = max(item[1] for item in annotation['points'])\n",
    "            width = max_x - min_x\n",
    "            height = max_y - min_y\n",
    "\n",
    "            coco_annotation = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": 1,\n",
    "                \"segmentation\": [[value for sublist in annotation['points'] for value in sublist]],\n",
    "                \"area\": width * height,\n",
    "                \"bbox\": [min_x, min_y, width, height],\n",
    "                \"iscrowd\": 0,\n",
    "            }\n",
    "            annotations.append(coco_annotation)\n",
    "            annotation_id += 1\n",
    "        img_id += 1\n",
    "    coco = {\n",
    "        'info' : info,\n",
    "        'images' : images,\n",
    "        'annotations' : annotations,\n",
    "        'licenses' : licenses,\n",
    "        'categories' : categories\n",
    "    }\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "ufo_to_coco(file['images'], output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 작업한 coco json파일 -> ufo  (o) tag 제외 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '../data/medical/ufo/instances_default.json'\n",
    "output_path = '../data/medical/ufo/train_coco_2_ufo.json'\n",
    "\n",
    "ufo = {\n",
    "    'images': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_bbox_to_ufo(bbox):\n",
    "    min_x, min_y, width, height = bbox\n",
    "    return [\n",
    "        [min_x, min_y],\n",
    "        [min_x + width, min_y],\n",
    "        [min_x + width, min_y + height],\n",
    "        [min_x, min_y + height]\n",
    "    ]\n",
    "\n",
    "def coco_to_ufo(file: Dict, output_path: str) -> None:\n",
    "    anno_id = 1\n",
    "    for annotation in file['annotations']:\n",
    "        file_info = file['images'][int(annotation['image_id'])-1]\n",
    "        image_name = file_info['file_name']\n",
    "        if image_name not in ufo['images']:\n",
    "            anno_id = 1\n",
    "            ufo['images'][image_name] = {\n",
    "                \"paragraphs\": {},\n",
    "                \"words\": {},\n",
    "                \"chars\": {},\n",
    "                \"img_w\": file_info[\"width\"],\n",
    "                \"img_h\": file_info[\"height\"],\n",
    "                \"tags\": [\"autoannotated\"],\n",
    "                \"relations\": {},\n",
    "                \"annotation_log\": {\n",
    "                    \"worker\": \"\",\n",
    "                    \"timestamp\": now,\n",
    "                    \"tool_version\": \"LabelMe or CVAT\",\n",
    "                    \"source\": None\n",
    "                    },\n",
    "                \"license_tag\": {\n",
    "                    \"usability\": True,\n",
    "                    \"public\": False,\n",
    "                    \"commercial\": True,\n",
    "                    \"type\": None,\n",
    "                    \"holder\": \"Upstage\"\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "            # anno_id = 1\n",
    "        ufo['images'][image_name]['words'][str(anno_id).zfill(4)] = {\n",
    "            \"transcription\": \"\",\n",
    "            \"points\":  coco_bbox_to_ufo(annotation[\"bbox\"]),\n",
    "            \"orientation\": \"Horizontal\",\n",
    "            \"language\": None,\n",
    "            \"tags\": 'Auto',  ## 이거 변경\n",
    "            \"confidence\": None,\n",
    "            \"illegibility\": False\n",
    "        }\n",
    "        anno_id += 1\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(ufo, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "coco_to_ufo(file, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옮겨둔 이미지와 일치하는 json파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/img'  # 폴더 경로\n",
    "files_ext = os.listdir(folder_path)  # 폴더 내의 파일 목록\n",
    "# 확장자를 제외한 파일명만 추출\n",
    "img_files = [os.path.splitext(file)[0] for file in files_ext]\n",
    "len(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# json 파일이 있는 폴더 경로\n",
    "json_source_folder = \"../data/medical/OCR/01.라벨링데이터(Json)\"\n",
    "\n",
    "# 이동시킬 폴더\n",
    "destination_json_folder = \"../data/medical/OCR/json\"\n",
    "\n",
    "# json 파일을 복사하며 이미지 파일과 동일한 이름인 경우에만 복사\n",
    "for root, dirs, files in os.walk(json_source_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            destination_json_name = os.path.splitext(file)[0]  # 확장자 제외한 파일 이름만 가져오기\n",
    "            destination_json_path = os.path.join(destination_json_folder, file)\n",
    "            if destination_json_name in img_files:\n",
    "                shutil.copy(source_file_path, destination_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_folder_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json'  # 폴더 경로\n",
    "json_files_ext = os.listdir(json_folder_path)  # 폴더 내의 파일 목록\n",
    "len(json_files_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom -> coco json파일 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{\n",
    "    'id': 1,\n",
    "    'name': 'word'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# JSON 파일이 있는 폴더 경로\n",
    "json_folder = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/'\n",
    "output_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/new_json.json'\n",
    "\n",
    "# 기존 정보\n",
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{'id': 1, 'name': 'word'}]\n",
    "\n",
    "# COCO 데이터 초기화\n",
    "img_id = 1\n",
    "annotation_id = 1\n",
    "images = []\n",
    "annotations = []\n",
    "\n",
    "for file_name in os.listdir(json_folder):\n",
    "    if file_name.endswith('.json'):\n",
    "        input_path = os.path.join(json_folder, file_name)\n",
    "\n",
    "        with open(input_path, 'r') as f:\n",
    "            file = json.load(f)\n",
    "        image = {\n",
    "            'id': img_id,\n",
    "            'width': file['images'][0]['image.width'],\n",
    "            'height': file['images'][0]['image.height'],\n",
    "            'file_name': file['images'][0][\"image.file.name\"],\n",
    "            \"license\": 1,\n",
    "            \"flickr_url\": None,\n",
    "            \"coco_url\": None,\n",
    "            'data_captured': file['images'][0][\"image.create.time\"]\n",
    "        }\n",
    "        images.append(image)\n",
    "\n",
    "        for ann_info in file['annotations']:\n",
    "            min_x = ann_info[\"annotation.bbox\"][0]\n",
    "            min_y = ann_info[\"annotation.bbox\"][1]\n",
    "            width = ann_info[\"annotation.bbox\"][2]\n",
    "            height = ann_info[\"annotation.bbox\"][3]\n",
    "\n",
    "            segmentation = [\n",
    "                            [min_x, min_y, min_x + width, min_y, min_x + width, min_y + height, min_x, min_y + height]\n",
    "                            ]\n",
    "\n",
    "            coco_annotation = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": 1,\n",
    "                \"segmentation\": segmentation,\n",
    "                \"area\": width * height,\n",
    "                \"bbox\": [min_x, min_y, width, height],\n",
    "                \"iscrowd\": 0,\n",
    "                'tags' : ['Auto']\n",
    "            }\n",
    "            annotations.append(coco_annotation)\n",
    "            annotation_id += 1\n",
    "\n",
    "        img_id += 1\n",
    "\n",
    "# 모든 데이터를 COCO 포맷으로 합치기\n",
    "coco = {\n",
    "    'info': info,\n",
    "    'images': images,\n",
    "    'annotations': annotations,\n",
    "    'licenses': licenses,  # 리스트로 변환\n",
    "    'categories': categories\n",
    "}\n",
    "\n",
    "# JSON 파일로 저장\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(coco, f, indent=4)\n",
    "\n",
    "# KeyError 0 나면, new_json.json가 이미 만들어져 있는 거임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coco -> ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# 커스텀 coco포맷 json파일 -> ufo포맷\n",
    "# input_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/new_json.json'\n",
    "# output_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/_new_json.json'\n",
    "\n",
    "# cvat작업 coco포맷 json파일 -> ufo포맷\n",
    "input_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/instances_default.json'\n",
    "output_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/_instances_default.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo = {\n",
    "    'images': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_bbox_to_ufo(bbox):\n",
    "    min_x, min_y, width, height = bbox\n",
    "    return [\n",
    "        [min_x, min_y],\n",
    "        [min_x + width, min_y],\n",
    "        [min_x + width, min_y + height],\n",
    "        [min_x, min_y + height]\n",
    "    ]\n",
    "\n",
    "def coco_to_ufo(file: Dict, output_path: str) -> None:\n",
    "    anno_id = 1\n",
    "    for annotation in file['annotations']:\n",
    "        file_info = file['images'][int(annotation['image_id'])-1]\n",
    "        image_name = file_info['file_name']\n",
    "        if image_name not in ufo['images']:\n",
    "            anno_id = 1\n",
    "            ufo['images'][image_name] = {\n",
    "                \"paragraphs\": {},\n",
    "                \"words\": {},\n",
    "                \"chars\": {},\n",
    "                \"img_w\": file_info[\"width\"],\n",
    "                \"img_h\": file_info[\"height\"],\n",
    "                \"tags\": [\"autoannotated\"],\n",
    "                \"relations\": {},\n",
    "                \"annotation_log\": {\n",
    "                    \"worker\": \"\",\n",
    "                    \"timestamp\": now,\n",
    "                    \"tool_version\": \"LabelMe or CVAT\",\n",
    "                    \"source\": None\n",
    "                    },\n",
    "                \"license_tag\": {\n",
    "                    \"usability\": True,\n",
    "                    \"public\": False,\n",
    "                    \"commercial\": True,\n",
    "                    \"type\": None,\n",
    "                    \"holder\": \"Upstage\"\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "            # anno_id = 1\n",
    "        ufo['images'][image_name]['words'][str(anno_id).zfill(4)] = {\n",
    "            \"transcription\": \"\",\n",
    "            \"points\":  coco_bbox_to_ufo(annotation[\"bbox\"]),\n",
    "            \"orientation\": \"Horizontal\",\n",
    "            \"language\": None,\n",
    "            \"tags\": annotation['tags'],\n",
    "            \"confidence\": None,\n",
    "            \"illegibility\": False\n",
    "        }\n",
    "        anno_id += 1\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(ufo, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     file \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mcoco_to_ufo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 46\u001b[0m, in \u001b[0;36mcoco_to_ufo\u001b[0;34m(file, output_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m         ufo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m][image_name] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparagraphs\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 }\n\u001b[1;32m     38\u001b[0m             }\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;66;03m# anno_id = 1\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     ufo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m][image_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mstr\u001b[39m(anno_id)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m4\u001b[39m)] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscription\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m:  coco_bbox_to_ufo(annotation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHorizontal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mannotation\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124millegibility\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     }\n\u001b[1;32m     50\u001b[0m     anno_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tags'"
     ]
    }
   ],
   "source": [
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "coco_to_ufo(file, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 json 파일과 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 json\n",
    "original_json_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/divided_train.json'\n",
    "# custom_json파일\n",
    "made_json_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/_new_json.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(original_json_path, 'r') as f:\n",
    "    file_1 = json.load(f)\n",
    "with open(made_json_path, 'r') as f:\n",
    "    file_2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path ='/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/_newest_.json'\n",
    "\n",
    "combined_images = {}\n",
    "combined_images = {**file_1['images'], **file_2['images']}\n",
    "\n",
    "combined_json = {\n",
    "    'images': combined_images\n",
    "}\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(combined_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_1['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_2['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_json['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 작업한 coco json파일에서 tag만 비교해서 들고오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 원본 JSON 파일 경로\n",
    "input_json_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/instances_default.json'\n",
    "\n",
    "# 들여쓰기를 적용한 JSON 파일 경로\n",
    "output_json_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/instances_default_formatted.json'\n",
    "\n",
    "# JSON 파일 불러오기\n",
    "with open(input_json_path, 'r') as input_file:\n",
    "    data = json.load(input_file)\n",
    "\n",
    "# 들여쓰기를 적용하여 JSON 파일 저장\n",
    "with open(output_json_path, 'w') as output_file:\n",
    "    json.dump(data, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
