{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 ufo json파일 -> coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '../data/medical/ufo/divided_train.json'\n",
    "# input_path = '../../data/medical/ufo/train.json'\n",
    "output_path = '../data/medical/ufo/train_coco.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "    'date_created': now\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{\n",
    "    'id': 1,\n",
    "    'name': 'word'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ufo_to_coco(file: Dict, output_path: str) -> None:\n",
    "    img_id = 1 #COCO는 1부터 시작\n",
    "    annotation_id = 1 #COCO는 1부터 시작\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for fname, data in file.items():\n",
    "        image = {\n",
    "            \"id\": img_id,\n",
    "            \"width\": data['img_w'],\n",
    "            \"height\": data['img_h'],\n",
    "            \"file_name\": fname,\n",
    "            \"license\": 1,\n",
    "            \"flickr_url\": None,\n",
    "            \"coco_url\": None,\n",
    "            \"date_captured\": now\n",
    "        }\n",
    "        images.append(image)\n",
    "        for anno_id, annotation in data['words'].items():\n",
    "            if annotation['illegibility'] == True:\n",
    "                continue\n",
    "            min_x = min(item[0] for item in annotation['points'])\n",
    "            min_y = min(item[1] for item in annotation['points'])\n",
    "            max_x = max(item[0] for item in annotation['points'])\n",
    "            max_y = max(item[1] for item in annotation['points'])\n",
    "            width = max_x - min_x\n",
    "            height = max_y - min_y\n",
    "            tags = annotation['tags']\n",
    "\n",
    "            coco_annotation = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": 1,\n",
    "                \"segmentation\": [[value for sublist in annotation['points'] for value in sublist]],\n",
    "                \"area\": width * height,\n",
    "                \"bbox\": [min_x, min_y, width, height],\n",
    "                \"iscrowd\": 0,\n",
    "                'tags' : tags\n",
    "            }\n",
    "            annotations.append(coco_annotation)\n",
    "            annotation_id += 1\n",
    "        img_id += 1\n",
    "    coco = {\n",
    "        'info' : info,\n",
    "        'images' : images,\n",
    "        'annotations' : annotations,\n",
    "        'licenses' : licenses,\n",
    "        'categories' : categories\n",
    "    }\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(coco, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "ufo_to_coco(file['images'], output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 파일 coco -> ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옮겨둔 이미지와 일치하는 json파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/img'  # 폴더 경로\n",
    "files_ext = os.listdir(folder_path)  # 폴더 내의 파일 목록\n",
    "# 확장자를 제외한 파일명만 추출\n",
    "img_files = [os.path.splitext(file)[0] for file in files_ext]\n",
    "len(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# json 파일이 있는 폴더 경로\n",
    "json_source_folder = \"../data/medical/OCR/01.라벨링데이터(Json)\"\n",
    "\n",
    "# 이동시킬 폴더\n",
    "destination_json_folder = \"../data/medical/OCR/json\"\n",
    "\n",
    "# json 파일을 복사하며 이미지 파일과 동일한 이름인 경우에만 복사\n",
    "for root, dirs, files in os.walk(json_source_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            destination_json_name = os.path.splitext(file)[0]  # 확장자 제외한 파일 이름만 가져오기\n",
    "            destination_json_path = os.path.join(destination_json_folder, file)\n",
    "            if destination_json_name in img_files:\n",
    "                shutil.copy(source_file_path, destination_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_folder_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json'  # 폴더 경로\n",
    "json_files_ext = os.listdir(json_folder_path)  # 폴더 내의 파일 목록\n",
    "len(json_files_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom -> coco json파일 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{\n",
    "    'id': 1,\n",
    "    'name': 'word'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# JSON 파일이 있는 폴더 경로\n",
    "json_folder = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/'\n",
    "output_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/new_json.json'\n",
    "\n",
    "# 기존 정보\n",
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{'id': 1, 'name': 'word'}]\n",
    "\n",
    "# COCO 데이터 초기화\n",
    "img_id = 1\n",
    "annotation_id = 1\n",
    "images = []\n",
    "annotations = []\n",
    "\n",
    "for file_name in os.listdir(json_folder):\n",
    "    if file_name.endswith('.json'):\n",
    "        input_path = os.path.join(json_folder, file_name)\n",
    "\n",
    "        with open(input_path, 'r') as f:\n",
    "            file = json.load(f)\n",
    "        image = {\n",
    "            'id': img_id,\n",
    "            'width': file['images'][0]['image.width'],\n",
    "            'height': file['images'][0]['image.height'],\n",
    "            'file_name': file['images'][0][\"image.file.name\"],\n",
    "            \"license\": 1,\n",
    "            \"flickr_url\": None,\n",
    "            \"coco_url\": None,\n",
    "            'data_captured': file['images'][0][\"image.create.time\"]\n",
    "        }\n",
    "        images.append(image)\n",
    "\n",
    "        for ann_info in file['annotations']:\n",
    "            min_x = ann_info[\"annotation.bbox\"][0]\n",
    "            min_y = ann_info[\"annotation.bbox\"][1]\n",
    "            width = ann_info[\"annotation.bbox\"][2]\n",
    "            height = ann_info[\"annotation.bbox\"][3]\n",
    "\n",
    "            segmentation = [\n",
    "                            [min_x, min_y, min_x + width, min_y, min_x + width, min_y + height, min_x, min_y + height]\n",
    "                            ]\n",
    "\n",
    "            coco_annotation = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": 1,\n",
    "                \"segmentation\": segmentation,\n",
    "                \"area\": width * height,\n",
    "                \"bbox\": [min_x, min_y, width, height],\n",
    "                \"iscrowd\": 0,\n",
    "                'tags' : ['Auto']\n",
    "            }\n",
    "            annotations.append(coco_annotation)\n",
    "            annotation_id += 1\n",
    "\n",
    "        img_id += 1\n",
    "\n",
    "# 모든 데이터를 COCO 포맷으로 합치기\n",
    "coco = {\n",
    "    'info': info,\n",
    "    'images': images,\n",
    "    'annotations': annotations,\n",
    "    'licenses': licenses,  # 리스트로 변환\n",
    "    'categories': categories\n",
    "}\n",
    "\n",
    "# JSON 파일로 저장\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(coco, f, indent=4)\n",
    "\n",
    "# KeyError 0 나면, new_json.json가 이미 만들어져 있는 거임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coco -> ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/new_json.json'\n",
    "output_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/_new_json.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo = {\n",
    "    'images': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_bbox_to_ufo(bbox):\n",
    "    min_x, min_y, width, height = bbox\n",
    "    return [\n",
    "        [min_x, min_y],\n",
    "        [min_x + width, min_y],\n",
    "        [min_x + width, min_y + height],\n",
    "        [min_x, min_y + height]\n",
    "    ]\n",
    "\n",
    "def coco_to_ufo(file: Dict, output_path: str) -> None:\n",
    "    anno_id = 1\n",
    "    for annotation in file['annotations']:\n",
    "        file_info = file['images'][int(annotation['image_id'])-1]\n",
    "        image_name = file_info['file_name']\n",
    "        if image_name not in ufo['images']:\n",
    "            anno_id = 1\n",
    "            ufo['images'][image_name] = {\n",
    "                \"paragraphs\": {},\n",
    "                \"words\": {},\n",
    "                \"chars\": {},\n",
    "                \"img_w\": file_info[\"width\"],\n",
    "                \"img_h\": file_info[\"height\"],\n",
    "                \"tags\": [\"autoannotated\"],\n",
    "                \"relations\": {},\n",
    "                \"annotation_log\": {\n",
    "                    \"worker\": \"\",\n",
    "                    \"timestamp\": now,\n",
    "                    \"tool_version\": \"LabelMe or CVAT\",\n",
    "                    \"source\": None\n",
    "                    },\n",
    "                \"license_tag\": {\n",
    "                    \"usability\": True,\n",
    "                    \"public\": False,\n",
    "                    \"commercial\": True,\n",
    "                    \"type\": None,\n",
    "                    \"holder\": \"Upstage\"\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "            # anno_id = 1\n",
    "        ufo['images'][image_name]['words'][str(anno_id).zfill(4)] = {\n",
    "            \"transcription\": \"\",\n",
    "            \"points\":  coco_bbox_to_ufo(annotation[\"bbox\"]),\n",
    "            \"orientation\": \"Horizontal\",\n",
    "            \"language\": None,\n",
    "            \"tags\": 'Auto',\n",
    "            \"confidence\": None,\n",
    "            \"illegibility\": False\n",
    "        }\n",
    "        anno_id += 1\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(ufo, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "coco_to_ufo(file, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 json 파일과 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 json\n",
    "original_json_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/divided_train.json'\n",
    "# custom_json파일\n",
    "made_json_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/_new_json.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(original_json_path, 'r') as f:\n",
    "    file_1 = json.load(f)\n",
    "with open(made_json_path, 'r') as f:\n",
    "    file_2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path ='/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/_newest_.json'\n",
    "\n",
    "combined_images = {}\n",
    "combined_images = {**file_1['images'], **file_2['images']}\n",
    "\n",
    "combined_json = {\n",
    "    'images': combined_images\n",
    "}\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(combined_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_1['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_2['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_json['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 외부 json 파일 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
