{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옮겨둔 이미지와 일치하는 json파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/img'  # 폴더 경로\n",
    "files_ext = os.listdir(folder_path)  # 폴더 내의 파일 목록\n",
    "# 확장자를 제외한 파일명만 추출\n",
    "img_files = [os.path.splitext(file)[0] for file in files_ext]\n",
    "len(img_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 jpg 파일을 복사했습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# json 파일이 있는 폴더 경로\n",
    "json_source_folder = \"../data/medical/OCR/01.라벨링데이터(Json)\"\n",
    "\n",
    "# 이동시킬 폴더\n",
    "destination_json_folder = \"../data/medical/OCR/json\"\n",
    "\n",
    "# json 파일을 복사하며 이미지 파일과 동일한 이름인 경우에만 복사\n",
    "for root, dirs, files in os.walk(json_source_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            destination_json_name = os.path.splitext(file)[0]  # 확장자 제외한 파일 이름만 가져오기\n",
    "            destination_json_path = os.path.join(destination_json_folder, file)\n",
    "            if destination_json_name in img_files:\n",
    "                shutil.copy(source_file_path, destination_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_folder_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json'  # 폴더 경로\n",
    "json_files_ext = os.listdir(json_folder_path)  # 폴더 내의 파일 목록\n",
    "len(json_files_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json파일 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{\n",
    "    'id': 1,\n",
    "    'name': 'word'\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     34\u001b[0m     file \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     35\u001b[0m image \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: img_id,\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mfile\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.width\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m: file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.height\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m: file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage.file.name\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlicense\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflickr_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_captured\u001b[39m\u001b[38;5;124m'\u001b[39m: file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage.create.time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     44\u001b[0m }\n\u001b[1;32m     45\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ann_info \u001b[38;5;129;01min\u001b[39;00m file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# JSON 파일이 있는 폴더 경로\n",
    "json_folder = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/'\n",
    "output_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/new_json.json'\n",
    "\n",
    "# 기존 정보\n",
    "info = {\n",
    "    'year': 2024,\n",
    "    'version': '1.0',\n",
    "    'description': 'OCR Competition Data',\n",
    "    'contributor': 'Naver Boostcamp',\n",
    "    'url': 'https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000273/data/data.tar.gz',\n",
    "}\n",
    "licenses = {\n",
    "    'id': '1',\n",
    "    'name': 'For Naver Boostcamp Competition',\n",
    "    'url': None\n",
    "}\n",
    "categories = [{'id': 1, 'name': 'word'}]\n",
    "\n",
    "# COCO 데이터 초기화\n",
    "img_id = 1\n",
    "annotation_id = 1\n",
    "images = []\n",
    "annotations = []\n",
    "\n",
    "for file_name in os.listdir(json_folder):\n",
    "    if file_name.endswith('.json'):\n",
    "        input_path = os.path.join(json_folder, file_name)\n",
    "\n",
    "        with open(input_path, 'r') as f:\n",
    "            file = json.load(f)\n",
    "        image = {\n",
    "            'id': img_id,\n",
    "            'width': file['images'][0]['image.width'],\n",
    "            'height': file['images'][0]['image.height'],\n",
    "            'file_name': file['images'][0][\"image.file.name\"],\n",
    "            \"license\": 1,\n",
    "            \"flickr_url\": None,\n",
    "            \"coco_url\": None,\n",
    "            'data_captured': file['images'][0][\"image.create.time\"]\n",
    "        }\n",
    "        images.append(image)\n",
    "\n",
    "        for ann_info in file['annotations']:\n",
    "            min_x = ann_info[\"annotation.bbox\"][0]\n",
    "            min_y = ann_info[\"annotation.bbox\"][1]\n",
    "            width = ann_info[\"annotation.bbox\"][2]\n",
    "            height = ann_info[\"annotation.bbox\"][3]\n",
    "\n",
    "            coco_annotation = {\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": 1,\n",
    "                \"area\": width * height,\n",
    "                \"bbox\": [min_x, min_y, width, height],\n",
    "                \"iscrowd\": 0\n",
    "            }\n",
    "            annotations.append(coco_annotation)\n",
    "            annotation_id += 1\n",
    "\n",
    "        img_id += 1\n",
    "\n",
    "# 모든 데이터를 COCO 포맷으로 합치기\n",
    "coco = {\n",
    "    'info': info,\n",
    "    'images': images,\n",
    "    'annotations': annotations,\n",
    "    'licenses': licenses,  # 리스트로 변환\n",
    "    'categories': categories\n",
    "}\n",
    "\n",
    "# JSON 파일로 저장\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(coco, f, indent=4)\n",
    "\n",
    "# KeyError 0 나면, new_json.json가 이미 만들어져 있는 거임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coco -> ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/new_json.json'\n",
    "output_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/_new_json.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo = {\n",
    "    'images': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_bbox_to_ufo(bbox):\n",
    "    min_x, min_y, width, height = bbox\n",
    "    return [\n",
    "        [min_x, min_y],\n",
    "        [min_x + width, min_y],\n",
    "        [min_x + width, min_y + height],\n",
    "        [min_x, min_y + height]\n",
    "    ]\n",
    "\n",
    "def coco_to_ufo(file: Dict, output_path: str) -> None:\n",
    "    anno_id = 1\n",
    "    for annotation in file['annotations']:\n",
    "        file_info = file['images'][int(annotation['image_id'])-1]\n",
    "        image_name = file_info['file_name']\n",
    "        if image_name not in ufo['images']:\n",
    "            anno_id = 1\n",
    "            ufo['images'][image_name] = {\n",
    "                \"paragraphs\": {},\n",
    "                \"words\": {},\n",
    "                \"chars\": {},\n",
    "                \"img_w\": file_info[\"width\"],\n",
    "                \"img_h\": file_info[\"height\"],\n",
    "                \"tags\": [\"re-annotated\"],\n",
    "                \"relations\": {},\n",
    "                \"annotation_log\": {\n",
    "                    \"worker\": \"\",\n",
    "                    \"timestamp\": now,\n",
    "                    \"tool_version\": \"LabelMe or CVAT\",\n",
    "                    \"source\": None\n",
    "                    },\n",
    "                \"license_tag\": {\n",
    "                    \"usability\": True,\n",
    "                    \"public\": False,\n",
    "                    \"commercial\": True,\n",
    "                    \"type\": None,\n",
    "                    \"holder\": \"Upstage\"\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "            # anno_id = 1\n",
    "        ufo['images'][image_name]['words'][str(anno_id).zfill(4)] = {\n",
    "            \"transcription\": \"\",\n",
    "            \"points\":  coco_bbox_to_ufo(annotation[\"bbox\"]),\n",
    "            \"orientation\": \"Horizontal\",\n",
    "            \"language\": None,\n",
    "            \"tags\": None,\n",
    "            \"confidence\": None,\n",
    "            \"illegibility\": False\n",
    "        }\n",
    "        anno_id += 1\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(ufo, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_path, 'r') as f:\n",
    "    file = json.load(f)\n",
    "coco_to_ufo(file, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기존 json 파일과 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 json\n",
    "original_json_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/train.json'\n",
    "# custom_json파일\n",
    "made_json_path = '/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/OCR/json/_new_json.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(original_json_path, 'r') as f:\n",
    "    file_1 = json.load(f)\n",
    "with open(made_json_path, 'r') as f:\n",
    "    file_2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path ='/data/ephemeral/home/level2-cv-datacentric-cv-10/data/medical/ufo/_newest_.json'\n",
    "\n",
    "combined_images = {}\n",
    "combined_images.update(file_2)\n",
    "combined_images.update(file_1)\n",
    "\n",
    "combined_images['images']\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(combined_images, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
